{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages necessary to create basic function for Kernel Perceptron\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function that allow to shift from a positive value to 1 and a negative value to -1. Used in perceptron algorithm\n",
    "def sign(value):\n",
    "    if value > 0:\n",
    "        fvalue = 1\n",
    "    elif value <= 0:\n",
    "        fvalue = -1\n",
    "    return fvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to compute the gram matrix, necessary to output the predictor from the learning algorithm\n",
    "def gram_poly(A, d):\n",
    "    \n",
    "    return np.float32((1 + np.matmul(A, A.T))**d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to compute the Kernel Matrix, necessary to make prediction given a predictor\n",
    "def kernel_poly(A, B, d):\n",
    "    \n",
    "    return np.float32((1 + np.matmul(A, B.T))**d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#extract a predictor (one vs all) at the end of each epochs\n",
    "def find_predictors(x_train, y_train, kernel, epochs, row):\n",
    "    saved_predictors = []\n",
    "    alpha = np.zeros((len(x_train)))\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(len(x_train)):\n",
    "            val= np.dot((alpha * y_train[:,row]),kernel[i,:])\n",
    "            val = sign(val)\n",
    "            if val != y_train[i, row]:\n",
    "                alpha[i] = alpha[i] + 1\n",
    "        predictor = alpha.copy()\n",
    "        saved_predictors.append(predictor)\n",
    "    return saved_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to take a binary final predictors at the end of each epoch and make the mean of each binary predictor.\n",
    "def mean_classifier(classifiers_list):\n",
    "    mean_classifier = []\n",
    "    for classifier in classifiers_list:\n",
    "        classifier_matrix = np.array(classifier)\n",
    "        classifier_matrix = classifier_matrix.mean(axis = 0)\n",
    "        mean_classifier.append(classifier_matrix)\n",
    "    mean_classifier = np.array(mean_classifier)\n",
    "    return(mean_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the set of a binary predictor (example: 2)\n",
    "#extract the one which minimize the training error for prediction of the number 2\n",
    "def define_bests(x_train, y_train, gram_matrix, predictors):\n",
    "    best_for_binary = []\n",
    "    for index, list_ in enumerate(predictors):\n",
    "        value_error = []\n",
    "        for ind, predictor in enumerate(list_):\n",
    "            wrong = 0\n",
    "            for i in range(len(x_train)):\n",
    "                s = np.dot((predictor*y_train[:,index]),gram_matrix[i,:])\n",
    "                s = sign(s)\n",
    "                if y_train[i,index] != s:\n",
    "                    wrong += 1 \n",
    "            value = (wrong / len(x_train))*100\n",
    "            value_error.append(value)\n",
    "        value_error = np.array(value_error)\n",
    "        index_min = np.argmin(value_error)\n",
    "        best = list_[index_min]\n",
    "        best_for_binary.append(best)\n",
    "    return(best_for_binary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to compute the accuracy of a predictor\n",
    "def accuracy_test(y_train, y_test, multi_best, kernel_matrix, x_train):\n",
    "    num_correct = 0\n",
    "    for i in range(len(y_test)):\n",
    "        predict = np.zeros(len(multi_best))\n",
    "        for j in range(len(multi_best)):\n",
    "                predict[j] =  np.dot((multi_best[j,:]*y_train[:, j]),kernel_matrix[i,:])\n",
    "        prediction = np.argmax(predict)\n",
    "        correct = np.argmax(y_test[i,:])\n",
    "        if prediction == correct:\n",
    "            num_correct += 1\n",
    "    percentage = (num_correct/ len(y_test))*100\n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that given the prediction and the real values, output the confusion matrix\n",
    "def confusion_matrix(y_train, y_test, multi_best, kernel_matrix, x_train):\n",
    "    num_correct = 0\n",
    "    conf_matrix = np.zeros(shape=(y_train.shape[1], y_train.shape[1]))\n",
    "    for i in range(len(y_test)):\n",
    "        predict = np.zeros(len(multi_best))\n",
    "        for j in range(len(multi_best)):\n",
    "                predict[j] =  np.dot((multi_best[j,:]*y_train[:, j]),kernel_matrix[i,:])\n",
    "        prediction = np.argmax(predict)\n",
    "        correct = np.argmax(y_test[i,:])\n",
    "        conf_matrix[correct, prediction] += 1\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to compute the training accuracy\n",
    "def accuracy_train(y_train, x_train, multi_best, kernel_matrix):\n",
    "    num_correct = 0\n",
    "    for i in range(len(y_train)):\n",
    "        predict = np.zeros(len(multi_best))\n",
    "        for j in range(len(multi_best)):\n",
    "            predict[j] = np.dot((multi_best[j,:]*y_train[:, j]),kernel_matrix[i,:])\n",
    "        prediction = np.argmax(predict)\n",
    "        correct = np.argmax(y_train[i,:])\n",
    "        if prediction == correct:\n",
    "            num_correct +=  1\n",
    "    percentage = (num_correct/ len(y_train))*100\n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main function: given a training set and test set, output the training accuracy and the test accuracy \n",
    "#for both the mean_predictor and the best_predictor\n",
    "def kernel_perceptron(x_train, x_test, y_train, y_test, dimensions, epochs):\n",
    "    gram = gram_poly(x_train, dimensions)\n",
    "    gram = np.float32(gram)\n",
    "    One_vs_all_predictors = []\n",
    "    for binary_classificators in range(y_train.shape[1]):\n",
    "        predictor = find_predictors(x_train, y_train, gram, epochs, binary_classificators) \n",
    "        One_vs_all_predictors.append(predictor)\n",
    "    kernel_test = kernel_poly(x_test, x_train, dimensions)\n",
    "    kernel_test = np.float32(kernel_test)\n",
    "    final_best_classificator = define_bests(x_train, y_train, gram, One_vs_all_predictors)\n",
    "    final_best_classificator = np.array(final_best_classificator)\n",
    "    mean_classificator = mean_classifier(One_vs_all_predictors)\n",
    "    result = []\n",
    "    n_test = accuracy_test(y_train, y_test, final_best_classificator, kernel_test, x_train)\n",
    "    result.append(n_test)\n",
    "    n_train = accuracy_train(y_train, x_train, final_best_classificator, gram)\n",
    "    result.append(n_train)\n",
    "    n_test = accuracy_test(y_train, y_test, mean_classificator, kernel_test, x_train)\n",
    "    result.append(n_test)\n",
    "    n_train = accuracy_train(y_train, x_train, mean_classificator, gram)\n",
    "    result.append(n_train)\n",
    "    conf_matrix_best = confusion_matrix(y_train, y_test, final_best_classificator, kernel_test, x_train)\n",
    "    result.append(conf_matrix_best)\n",
    "    conf_matrix_mean = confusion_matrix(y_train, y_test, mean_classificator, kernel_test, x_train)\n",
    "    result.append(conf_matrix_mean)\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function used to compute true positive, false negative, true positive e true negative and \n",
    "#consequently the precision and the recall, that are measures that could be very usefull\n",
    "def metrics(conf_matrix):\n",
    "    TP = np.diag(conf_matrix)\n",
    "    FP = np.sum(conf_matrix, axis=0) - TP\n",
    "    FN = np.sum(conf_matrix, axis=1) - TP\n",
    "    num_classes = 10\n",
    "    TN = []\n",
    "    for i in range(num_classes):\n",
    "        temp = np.delete(conf_matrix, i, 0)    # delete ith row\n",
    "        temp = np.delete(temp, i, 1)  # delete ith column\n",
    "        TN.append(sum(sum(temp)))\n",
    "    metric = []\n",
    "    precision = TP/(TP+FP)\n",
    "    metric.append(precision)\n",
    "    recall = TP/(TP+FN)\n",
    "    metric.append(recall)\n",
    "    return(metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
